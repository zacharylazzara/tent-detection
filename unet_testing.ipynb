{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDBAp5Ib8BY+gkNOIbDSuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacharylazzara/tent-detection/blob/main/unet_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxCyr2CmiKAq",
        "outputId": "b0f94d1e-b65d-48d1-dcf6-8034d07991b7"
      },
      "source": [
        "# Setting environment variables\n",
        "\n",
        "%env S_PATH=/content/sarpol-zahab-tents/data\n",
        "%env U_PATH=/content/unet\n",
        "%env D_PATH=/content/unet/data/tent\n",
        "%env T_PATH=/content/unet/data/tent/train\n",
        "%env I_PATH=/content/unet/data/tent/train/image\n",
        "%env L_PATH=/content/unet/data/tent/train/label\n",
        "%env A_PATH=/content/unet/data/tent/train/aug\n",
        "%env V_PATH=/content/unet/data/tent/test\n",
        "%env N_PATH=/content/unet/data/tent/npydata"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: S_PATH=/content/sarpol-zahab-tents/data\n",
            "env: U_PATH=/content/unet\n",
            "env: D_PATH=/content/unet/data/tent\n",
            "env: T_PATH=/content/unet/data/tent/train\n",
            "env: I_PATH=/content/unet/data/tent/train/image\n",
            "env: L_PATH=/content/unet/data/tent/train/label\n",
            "env: A_PATH=/content/unet/data/tent/train/aug\n",
            "env: V_PATH=/content/unet/data/tent/test\n",
            "env: N_PATH=/content/unet/data/tent/npydata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU0MOSjqSa2_",
        "outputId": "b500c016-e567-48b0-d96d-939375601c48"
      },
      "source": [
        "# Preparing directories\n",
        "# TODO: make sure we pull the specific version of unet and the dataset so that if they change in the future we don't need to update the code\n",
        "\n",
        "\n",
        "%%bash\n",
        "if [ ! -d $S_PATH ]; then\n",
        " git clone https://github.com/tofighi/sarpol-zahab-tents.git\n",
        " git clone https://github.com/zhixuhao/unet.git\n",
        " \n",
        " rm -r $U_PATH/data\n",
        " rm -r $U_PATH/img\n",
        " \n",
        " mkdir -p $I_PATH\n",
        " mkdir -p $L_PATH\n",
        " mkdir -p $A_PATH\n",
        " \n",
        " mkdir -p $V_PATH\n",
        " mkdir -p $N_PATH\n",
        "\n",
        " rm -r /content/sample_data\n",
        "fi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'sarpol-zahab-tents'...\n",
            "Cloning into 'unet'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlbRI5dCR6zo"
      },
      "source": [
        "# Image Processing\n",
        "\n",
        "#From: https://medium.com/coinmonks/learn-how-to-train-u-net-on-your-dataset-8e3f89fbd623\n",
        "#Fit the data into a 256*256 format and save it as a .tif file\n",
        "\n",
        "from os import environ\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "s_path = environ.get(\"S_PATH\")\n",
        "t_path = environ.get(\"T_PATH\")\n",
        "v_path = environ.get(\"V_PATH\")\n",
        "\n",
        "# TODO: make sure these lists are in the same order\n",
        "imgs = list(map(Image.open, glob(\"{}/images/*\".format(s_path))))\n",
        "lbls = list(map(Image.open, glob(\"{}/labels/*\".format(s_path))))\n",
        "\n",
        "if len(imgs) == len(lbls):\n",
        "  n = len(imgs)\n",
        "\n",
        "  for i in range(n):\n",
        "    # TODO: check that file names are the same\n",
        "    # Any image modifications (cropping, etc) should be done here, before img.save()\n",
        "    if i < n/2: # TODO: come up with a better way to divide the dataset\n",
        "      imgs[i].save(\"{}/{}.png\".format(v_path, i)) # we need to put some data in the test directory\n",
        "    else:\n",
        "      imgs[i].save(\"{}/image/{}.tif\".format(t_path, i))\n",
        "      lbls[i].save(\"{}/label/{}.tif\".format(t_path, i))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyVKGFR3SaPu"
      },
      "source": [
        "# Modifying unet\n",
        "%%bash\n",
        "sed -i '8s/.*/from tensorflow.keras.optimizers import Adam/' unet/model.py\n",
        "sed -i '55s/.*/    model = Model(inputs, conv10)/' unet/model.py\n",
        "sed -i \"s/membrane/tent/\" unet/main.py\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuci0BaZn0TH",
        "outputId": "bef22105-8a16-40b3-c2fb-84f317f83251"
      },
      "source": [
        "# Running dataPrepare.ipynb\n",
        "%cd unet/\n",
        "\n",
        "from data import *\n",
        "\n",
        "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
        "#data_gen_args = dict()\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGenerator = trainGenerator(20,'data/tent/train','image','label',data_gen_args,save_to_dir = \"data/tent/train/aug\")\n",
        "\n",
        "\n",
        "#you will see 60 transformed images and their masks in data/membrane/train/aug\n",
        "num_batch = 3\n",
        "for i,batch in enumerate(myGenerator):\n",
        "    if(i >= num_batch):\n",
        "        break\n",
        "\n",
        "\n",
        "image_arr,mask_arr = geneTrainNpy(\"data/tent/train/aug/\",\"data/tent/train/aug/\")\n",
        "np.save(\"data/image_arr.npy\",image_arr)\n",
        "np.save(\"data/mask_arr.npy\",mask_arr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/unet\n",
            "Found 128 images belonging to 1 classes.\n",
            "Found 128 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E57pEsb2l3_",
        "outputId": "589aa657-8cc4-4c3f-9896-96b247343fc5"
      },
      "source": [
        "# Train Unet (trainUnet.ipynb)\n",
        "\n",
        "from model import *\n",
        "from data import *\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,'data/tent/train','image','label',data_gen_args,save_to_dir = None)\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_tent.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "#model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])\n",
        "model.fit_generator(myGene,steps_per_epoch=2,epochs=5,callbacks=[model_checkpoint])\n",
        "\n",
        "imgs_train,imgs_mask_train = geneTrainNpy(\"data/tent/train/aug/\",\"data/tent/train/aug/\")\n",
        "model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
        "\n",
        "testGene = testGenerator(\"data/tent/test\")\n",
        "model = unet()\n",
        "model.load_weights(\"unet_tent.hdf5\")\n",
        "results = model.predict(testGene,30,verbose=1)\n",
        "saveResult(\"data/tent/test\",results)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 128 images belonging to 1 classes.\n",
            "Found 128 images belonging to 1 classes.\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 37s 466ms/step - loss: 0.2660 - accuracy: 0.9904\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.26604, saving model to unet_tent.hdf5\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 475ms/step - loss: 0.0444 - accuracy: 0.9984\n",
            "\n",
            "Epoch 00002: loss improved from 0.26604 to 0.04443, saving model to unet_tent.hdf5\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 488ms/step - loss: 0.0696 - accuracy: 0.9967\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.04443\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.0740 - accuracy: 0.9955\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.04443\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.0491 - accuracy: 0.9977\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.04443\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 19s 565ms/step - loss: 0.0338 - accuracy: 0.9975 - val_loss: 0.0319 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00001: loss improved from 0.04443 to 0.03377, saving model to unet_tent.hdf5\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 17s 523ms/step - loss: 0.0304 - accuracy: 0.9975 - val_loss: 0.0335 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00002: loss improved from 0.03377 to 0.03039, saving model to unet_tent.hdf5\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 17s 528ms/step - loss: 0.0315 - accuracy: 0.9975 - val_loss: 0.0285 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.03039\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 18s 566ms/step - loss: 0.0293 - accuracy: 0.9975 - val_loss: 0.0266 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00004: loss improved from 0.03039 to 0.02932, saving model to unet_tent.hdf5\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 18s 564ms/step - loss: 0.0333 - accuracy: 0.9975 - val_loss: 0.0275 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.02932\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 17s 530ms/step - loss: 0.0293 - accuracy: 0.9975 - val_loss: 0.0285 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00006: loss improved from 0.02932 to 0.02930, saving model to unet_tent.hdf5\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 18s 564ms/step - loss: 0.0242 - accuracy: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00007: loss improved from 0.02930 to 0.02416, saving model to unet_tent.hdf5\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 18s 567ms/step - loss: 0.0266 - accuracy: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.02416\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 18s 565ms/step - loss: 0.0245 - accuracy: 0.9975 - val_loss: 0.0297 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.02416\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 18s 564ms/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.0190 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00010: loss improved from 0.02416 to 0.02253, saving model to unet_tent.hdf5\n",
            "30/30 [==============================] - 6s 110ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/unet/data.py:124: UserWarning: data/tent/test/0_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/1_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/2_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/3_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/4_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/5_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/6_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/7_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/8_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/9_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/10_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/11_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/12_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/13_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/14_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/15_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/16_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/17_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/18_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/19_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/20_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/21_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/22_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/23_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/24_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/25_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/26_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/27_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/28_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/unet/data.py:124: UserWarning: data/tent/test/29_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        }
      ]
    }
  ]
}