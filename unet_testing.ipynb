{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8OTvr0MSpPTT+0tJlgdvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacharylazzara/tent-detection/blob/main/unet_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxCyr2CmiKAq",
        "outputId": "238f1441-e24a-4d51-ba49-ceda642b8fec"
      },
      "source": [
        "# Setting environment variables\n",
        "\n",
        "%env S_PATH=/content/sarpol-zahab-tents/data\n",
        "%env U_PATH=/content/unet\n",
        "%env D_PATH=/content/unet/data/tent\n",
        "%env T_PATH=/content/unet/data/tent/train\n",
        "%env I_PATH=/content/unet/data/tent/train/image\n",
        "%env L_PATH=/content/unet/data/tent/train/label\n",
        "%env A_PATH=/content/unet/data/tent/train/aug\n",
        "%env V_PATH=/content/unet/data/tent/test\n",
        "%env N_PATH=/content/unet/data/tent/npydata"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: S_PATH=/content/sarpol-zahab-tents/data\n",
            "env: U_PATH=/content/unet\n",
            "env: D_PATH=/content/unet/data/tent\n",
            "env: T_PATH=/content/unet/data/tent/train\n",
            "env: I_PATH=/content/unet/data/tent/train/image\n",
            "env: L_PATH=/content/unet/data/tent/train/label\n",
            "env: A_PATH=/content/unet/data/tent/train/aug\n",
            "env: V_PATH=/content/unet/data/tent/test\n",
            "env: N_PATH=/content/unet/data/tent/npydata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU0MOSjqSa2_",
        "outputId": "96f57001-29db-43a3-c81c-f9df48f7b65d"
      },
      "source": [
        "# Preparing directories\n",
        "# TODO: make sure we pull the specific version of unet and the dataset so that if they change in the future we don't need to update the code\n",
        "\n",
        "%%bash\n",
        "if [ ! -d $S_PATH ]; then\n",
        " git clone https://github.com/tofighi/sarpol-zahab-tents.git\n",
        " git clone https://github.com/zhixuhao/unet.git\n",
        " \n",
        " rm -r $U_PATH/data\n",
        " rm -r $U_PATH/img\n",
        " \n",
        " mkdir -p $I_PATH\n",
        " mkdir -p $L_PATH\n",
        " mkdir -p $A_PATH\n",
        " \n",
        " mkdir -p $V_PATH\n",
        " mkdir -p $N_PATH\n",
        "\n",
        " rm -r /content/sample_data\n",
        "fi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'sarpol-zahab-tents'...\n",
            "Cloning into 'unet'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlbRI5dCR6zo"
      },
      "source": [
        "# Image Processing\n",
        "\n",
        "#From: https://medium.com/coinmonks/learn-how-to-train-u-net-on-your-dataset-8e3f89fbd623\n",
        "#Fit the data into a 256*256 format and save it as a .tif file\n",
        "\n",
        "\n",
        "# TODO: need to resize the image to a size unet expects\n",
        "\n",
        "from os import environ\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "s_path = environ.get(\"S_PATH\")\n",
        "t_path = environ.get(\"T_PATH\")\n",
        "v_path = environ.get(\"V_PATH\")\n",
        "\n",
        "\n",
        "#input_images = [np.asarray(Image.open(path).resize((192,192))) for path in sorted(glob(\"{}/labels/*\".format(s_path)))]\n",
        "#target_masks = [np.asarray(Image.open(path).resize((192,192))) for path in sorted(glob(\"{}/images/*\".format(s_path)))]\n",
        "\n",
        "\n",
        "# TODO: make sure these lists are in the same order\n",
        "imgs = list(map(Image.open, sorted(glob(\"{}/images/*\".format(s_path)))))\n",
        "lbls = list(map(Image.open, sorted(glob(\"{}/labels/*\".format(s_path)))))\n",
        "\n",
        "if len(imgs) == len(lbls):\n",
        "  n = len(imgs)\n",
        "\n",
        "  for i in range(n):\n",
        "    # TODO: check that file names are the same\n",
        "    # Any image modifications (cropping, etc) should be done here, before img.save()\n",
        "\n",
        "    imgs[i] = imgs[i].convert(\"RGB\").resize((256, 256))\n",
        "    lbls[i] = lbls[i].convert(\"RGB\").resize((256, 256))\n",
        "\n",
        "\n",
        "    if i < n/2: # TODO: come up with a better way to divide the dataset\n",
        "      imgs[i].save(\"{}/{}.png\".format(v_path, i)) # we need to put some data in the test directory\n",
        "      lbls[i].save(\"{}/{}_actual.png\".format(v_path, i))\n",
        "    else:\n",
        "      imgs[i].save(\"{}/image/{}.tif\".format(t_path, i))\n",
        "      lbls[i].save(\"{}/label/{}.tif\".format(t_path, i))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyVKGFR3SaPu"
      },
      "source": [
        "# Modifying unet\n",
        "%%bash\n",
        "sed -i '8s/.*/from tensorflow.keras.optimizers import Adam/' unet/model.py\n",
        "sed -i '55s/.*/    model = Model(inputs, conv10)/' unet/model.py\n",
        "sed -i \"s/membrane/tent/\" unet/main.py\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuci0BaZn0TH",
        "outputId": "fde87bd4-dd88-40fe-e7ab-3577bcc9702a"
      },
      "source": [
        "# Running dataPrepare.ipynb\n",
        "%cd unet/\n",
        "\n",
        "from data import *\n",
        "\n",
        "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
        "#data_gen_args = dict()\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGenerator = trainGenerator(20,'data/tent/train','image','label',data_gen_args,save_to_dir = \"data/tent/train/aug\")\n",
        "\n",
        "\n",
        "#you will see 60 transformed images and their masks in data/membrane/train/aug\n",
        "num_batch = 3\n",
        "for i,batch in enumerate(myGenerator):\n",
        "    if(i >= num_batch):\n",
        "        break\n",
        "\n",
        "\n",
        "image_arr,mask_arr = geneTrainNpy(\"data/tent/train/aug/\",\"data/tent/train/aug/\")\n",
        "np.save(\"data/image_arr.npy\",image_arr)\n",
        "np.save(\"data/mask_arr.npy\",mask_arr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/unet\n",
            "Found 128 images belonging to 1 classes.\n",
            "Found 128 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E57pEsb2l3_",
        "outputId": "ab0286c5-38f2-436f-dc66-87a0624afb2d"
      },
      "source": [
        "# Train Unet (trainUnet.ipynb)\n",
        "\n",
        "from model import *\n",
        "from data import *\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,'data/tent/train','image','label',data_gen_args,save_to_dir = None)\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_tent.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])\n",
        "\n",
        "imgs_train,imgs_mask_train = geneTrainNpy(\"data/tent/train/aug/\",\"data/tent/train/aug/\")\n",
        "model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
        "\n",
        "testGene = testGenerator(\"data/tent/test\")\n",
        "model = unet()\n",
        "model.load_weights(\"unet_tent.hdf5\")\n",
        "results = model.predict(testGene,30,verbose=1)\n",
        "saveResult(\"data/tent/test\",results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 128 images belonging to 1 classes.\n",
            "Found 128 images belonging to 1 classes.\n",
            "Epoch 1/5\n",
            " 513/2000 [======>.......................] - ETA: 12:06 - loss: 0.0263 - accuracy: 0.9985"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iK9OI-E-NlY"
      },
      "source": [
        "# View Results\n",
        "\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "v_path = environ.get(\"V_PATH\")\n",
        "\n",
        "p_lbls = np.array([np.asarray(Image.open(path).convert('RGB')) for path in sorted(glob(\"{}/*predict.png\".format(v_path)))])\n",
        "a_lbls = np.array([np.asarray(Image.open(path).convert('RGB')) for path in sorted(glob(\"{}/*actual.png\".format(v_path)))][:p_lbls.shape[0]])\n",
        "\n",
        "print(\"label shape: (count, width, height, channels)\")\n",
        "print(\"a_lbl shape: \", a_lbls.shape)\n",
        "print(\"p_lbl shape: \", p_lbls.shape)\n",
        "\n",
        "# If shapes aren't equal this won't work\n",
        "c_lbls = np.array([img for arr in np.stack((a_lbls, p_lbls), axis=1) for img in arr])\n",
        "\n",
        "print(\"c_lbl shape: \", c_lbls.shape)\n",
        "\n",
        "n = int(c_lbls.shape[0]/2)\n",
        "\n",
        "fig = plt.figure(figsize=(c_lbls.shape[1], c_lbls.shape[2]))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(n, 2), axes_pad=0.5)\n",
        "\n",
        "for ax, im in zip(grid, c_lbls):\n",
        "  ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}